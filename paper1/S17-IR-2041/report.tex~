\documentclass[9pt,twocolumn,twoside]{styles/osajnl}
\usepackage{fancyvrb}
\journal{i524}
\title{Tajo: A Distributed Warehouse System for Large Datasets}

\author[1]{Sagar Vora}

\affil[1]{School of Informatics and Computing, Bloomington, IN 47408, U.S.A.}

\dates{\today}

\ociscodes{HadoopDB, Hive, Distributed, MapReduce, Cluster, Query processing}

% replace this with your url in github/gitlab
\doi{\url{https://github.com/vorasagar7/sp17-i524/paper1/S17-IR-2041/report.pdf}}


\begin{abstract}

\cite{tajo-paper} There has been an increase in the volume of
relational data generated today through a large number of sources. The
large volume of data forces us to find solutions which can cope with
them. Recently several hybrid approaches like HadoopDB, Hive, etc)
have been introduced to handle this large data. Although these have
been successful in handling large data, but their architecture makes
them inefficient to handle suboptimal execution strategies. Therefore,
in order to solve the above problem, Apache has developed Tajo, a
relational, distributed data warehouse system on large clusters. It
uses Hadoop Distributed File System (HDFS) for storing data and has
its own query execution engine instead of the MapReduce
framework. \newline
\end{abstract}

% \setboolean{displaycopyright}{true}

\begin{document}

\maketitle

\section{Introduction}
In this Big Data era,\cite{www-apache-hadoop} \cite{mapreduce-article}
Hadoop MapReduce, has been used for processing large-scale data
sets. To handle a large amount of data, several hybrid approaches have
been integrated with Hadoop and parallel databases. However, these
cannot avoid the choice of suboptimal execution strategies because of
their architecture, which leads to the development of Tajo. Tajo is a
relational, distributed data warehouse system which runs on
shared-nothing clusters. It uses Hadoop Distributed File System (HDFS)
as the storage layer and has its own query execution engine instead of
the MapReduce framework. A Tajo cluster consists of one master node
and a number of workers. The master is responsible for the query
planning and coordination among the workers. \newline \newline The
internals of Tajo has three main steps. 1) Each worker has a local
query engine that executes a [7]directed acyclic graph (DAG) of
physical operators. A DAG of operators can accommodate multiple
sources of input and can be pipelined within the local query
engine. Each worker generates query execution plan that can employ the
existing query evaluation technique [5][6] which lie in the database
community. Tajo can make use of various repartition methods
specialized for specific queries. Consider joining two relations which
are already sorted on the join key, Tajo needs to repartition only one
relation to workers in which the corresponding part of another
relation resides. 3) In Tajo, a physical plan that a worker executes
is generated in runtime according to the available resources like
memory, processing capability etc. of the workers. Workers can
simultaneously execute different physical plans in the same phase
which allows Tajo to maximize the utilization of the resources.

\section{Advantages of Tajo over MapReduce Hive}
The limitations of Hadoop MapReduce-Hive technology due to its
architecture led to the development of Tajo. These limitations are as
follows:- \newline \newline Single Source Input: The join operation in
relational data warehouses integrates heterogeneous data sets from
multiple sources. But MapReduce supports only a single input source,
the join operation is performed by dividing input relations through
one map reduce job only which doesn't produce optimal
results.\newline \newline Fixed Data Flow: The 3 phases of MapReduce
are the map, shuffle, and sort and reduce. The join operation and
aggregation are performed in shuffle and sort phase. So it always
follows a fixed execution flow leaving no room for any optimization
needed in the processing. Sometimes processing huge datasets need to
follow some hybrid map reduce flow which is not applicable to the
Hadoop MapReduce framework. \newline \newline Separate Storage: Some
hybrid approaches [3] using the database layer require separate data
storages for data distribution and processing. In Hadoop, it takes a
long time for data loads causing other running workloads in the
cluster because of a separate data storage layer on the
HDFS.\newline \newline All of the above-mentioned shortcomings have
been overcome in Tajo.
cluster nodes report their resource information like the number of
available processors, memory usages, and remaining disk spaces
periodically to the cluster manager. The catalog maintains various
metadata, such as tables, schemas, partitions, functions, indices, and
statistics. Since the metadata are frequently accessed by the global
query engine, they are stored in a conventional RDBMS. The global
query engine builds a global plan based on the metadata of tables and
cluster information which are provided from the catalog and the
cluster manager, respectively. Finally, the history manager records the
metadata of the executed queries, including query statements,
statistics, and logical plans.

\subsection{Worker}

A worker has a query execution engine that performs assigned query. A
query unit contains a logical plan and fragments. A fragment is chunk
information of an input relation. During execution, a worker sends
periodically the reports of the running queries and the resource
status to the master which aids in failure.

\section{Query Processing}
Tajo has an SQL-like query language, called Tajo Query Language (TQL)
which supports most of the SQL coSDmmands. In addition to this, TQL also
supports two kinds of variables to indicate a scala value and a
temporary table respectively.

\subsection{Query Planning}

Figure \ref{fig:queryplanning} shows the steps involved in query transformation. 

\begin{figure}[htbp]
\centering
\fbox{\includegraphics[width=\linewidth]{images/queryplanning}}
\caption{\cite{tajopaper} Query Transformation}
\label{fig:queryplanning}
\end{figure}

Tajo has multiple steps to transform a query statement to physical
execution plans. When a user submits a query, the global query engine
parses the query into an abstract syntax tree and compiles it into a
logical plan. The query optimizer finds the best logical plan which is
similar to the original logical plan. This is the optimized logical
plan which is transformed into a global query plan. In this step, some
logical operators like group-by, sort, and join are transformed into
two phase with appropriate repartition methods. Usually, the first
phase computes local data on each node, and the intermediate data are
range-partitioned or hash-partitioned on the specified keys (e.g.,
sort keys, grouping keys). The second phase computes the partitioned
data on each node. As a result, a global query plan forms of a
directed acyclic graph (DAG) of subqueries, which represents a data
flow.Based on the physical information of the table, a subquery is
MapReduce Hive framework and provides distributed data warehouse
capabilities. By supporting SQL standards and advanced database
techniques, Tajo allows direct control of distributed execution and
data flow across a variety of query evaluation strategies and
optimization opportunities.Lastly, being compatible with ANSI/ISO SQL
standard, JDBC driver and various file formats such as CSV, JSON,
RCFile etc extends its capabilities further.

\section*{Acknowledgements}

I would like to thank my professor Gregor von Laszewski and all the
associate instructors for their constant technical support.

% Bibliography

\bibliography{references}
 


\newpage

\appendix


\end{document}
