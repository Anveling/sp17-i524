\documentclass[9pt,twocolumn,twoside]{styles/osajnl}
\usepackage{fancyvrb}
\journal{i524} 

\title{CDAP Cask Data Application Platform}

\author[1,*, +]{Avadhoot Agasti}

\affil[1]{School of Informatics and Computing, Bloomington, IN 47408, U.S.A.}

\affil[*]{Corresponding authors: aagasti@indiana.edu}

\affil[+]{HID - SL-IO-3000}

\dates{project-000, \today}

\ociscodes{CDAP, Hadoop}

% replace this with your url in github/gitlab
\doi{\url{https://github.com/avadhoot-agasti/sp17-i524/tree/master/paper1/S17-IO-3000/report.pdf}}


\begin{abstract}
This paper explains CDAP - Cask Data Application Platform. CDAP provides
abstraction layer on top of Apache Hadoop and other Apache Big Data Stack
technologies. This paper explains CDAP technology, the kind of problems it
can solve, the infrastructure and setup requirements, and its competitive
landscape. The paper also provides links to learning material for CDAP.
\newline
\end{abstract}

\setboolean{displaycopyright}{true}

\begin{document}

\maketitle

\section{Introduction}

CDAP stands for Cask Data Application Platform. CDAP is an application
development platform using which developers can build, deploy and monitor
applications on Apache Hadoop. In a typical CDAP application, a developer can
ingest data, store and manage datasets on Hadoop, perform batch mode data
analysis, and develop web services to expose the data.
They can also schedule and monitor the execution of the application. This way,
CDAP enables the developers to use single platform to develop the end to end
application on Apache Hadoop.
This paper introduces CDAP as application development platform and explains
various use cases that can be solved using CDAP. The paper also explains the
CDAP deployment options and infrastructure requirements.
Finally we conclude by explaining the other similar platforms and their high
level comparison with CDAP.
The paper also provides references to the learning material.

\section{Why CDAP}
Before we understand how CDAP helps in application development, lets understand
how a typical application looks like in Hadoop.

\subsection{Typical Application Architecture on Hadoop}
Figure 1 shows a typical application architecture on Hadoop.


\begin{figure}[htbp]
\centering
\fbox{\includegraphics[width=\linewidth]{images/hadoop-application-arch.png}}
\caption{Typical Application Architecture on Hadoop.}
\label{fig:hadoop-arch}
\end{figure}

There are following layers/components -

\begin{itemize}
\item Data Ingestion - ingest the data from data source into Hadoop.
Data Ingestion tools like Apache Sqoop, Apache Flume, Apache Kafka are
popularly used for Data Ingestion
\item Data Storage - The data is stored in HDFS.
\item Data Processing - The data is transformed and aggregated in Data
Processing layer. The processing can involved various steps like cleansing,
joining, aggregation and running machine learning algorithms. Many different
tools and technologies are used to perform data processing operations - e.g.
PIG, Hive, Spark are popular open source scripting technologies while
Talend, Informatica are visual commercial products.
\item Result Storage - The output of data processing step is again stored in
HDFS
\item Data Access - The end users can access the data (mainly results)
using various data access mechanism like APIs, SQL interface or BI tool
interface.
\end{itemize}

\subsection{Why CDAP - CDAP Application Architecture}
CDAP provides a common application development platform in which a developer
can code all the application layers in a typical Hadoop application. CDAP
provides abstractions to ingest data, store it in HDFS, process it using
the application business logic, store the results in HDFS and expose web
service APIs on the result data. User need not use different tools to code
different layers. He can simply code all the layers in CDAP platform. He can
use same coding language (Java) to do the coding across all the layers.

Further CDAP uses native Hadoop tools for actually performing the operations.
 For example, the data processing operation implemented in CDAP translate to
 Spark jobs. Due to this, CDAP users continue to leverage the new
 enhancements in Apache Hadoop.


\section{Important CDAP Concepts}
CDAP revolves around below important concepts:
\begin{itemize}
\item CDAP Datasets provide logical abstraction over the data stored in
Hadoop. The data can be files in HDFS or tables in HBase. A dataset needs to
be first declared in the CDAP. Any dataset declared in CDAP can be used in
any CDAP applications or CDAP services.
\item CDAP Applications provide containers to implement application business
logic in open source processing frameworks like map reduce, Spark and real
time flow. CDAP applications also provide standardize way to deploy and
manage the apps
\item CDAP Services provide services for application management, metadata
management, and streams management
\end{itemize}

\section{CDAP Deployment}
CDAP provides many deployment options. In standalone mode, it can be
downloaded as a zip file and deployed.
Alternatively it is available as a standalone virtual machine.
For cluster mode deployment, CDAP provides Hadoop-distribution specific
options as explained below
\begin{itemize}
\item Cloudera Hadoop Distribution (CDH) - Cloudera Manager is tool to
 deploy CDH cluster. As per CDAP documentation
\cite{www-cdap-cloudera-manager} CDAP provides CDAP-parcel which is plug in for
Cloudera Manager. Once you add CDAP-parcel
to your Cloudera Manager, CDAP can be deployed using Cloudera Manager and all
 CDAP services can be monitored using Cloudera Manager
\item Amazon EMR (Elastic Map Reduce) - EMR is Amazon's Hadoop distribution
for the Amazon Web Services cloud. EMR provides 'Create Cluster Wizard' to
create EMR cluster. According the CDAP documentation \cite{www-cdap-emr}, CDAP
provides a bootstrap action which is executed when the EMR cluster is created
. Using this mechanism, CDAP platform can be deployed on EMR when the EMR
cluster is created.
\end{itemize}
CDAP can also be deployed on HortonWorks Hadoop Distribution, MapR Hadoop
Distribution and Apache Hadoop.



\section{CDAP Infrastructure Requirements}

CDAP is deployed on edge nodes of the Hadoop cluster. CDAP communicates with
Hadoop services like Yarn, HDFS and HBase. Hence CDAP needs to be installed
in same network as that of Hadoop. However, none of the CDAP components are
required to be installed on Hadoop Namenode or Hadoop datanodes. CDAP
documentation \cite{www-cdap-deployment} provide the CDAP deployment
architecture.

\section{Educational Material}

\begin{itemize}
\item CDPA Applications code repository in Github \cite{github-cdap-apps}
provide sample applications which are built on top of CDAP Platform.
\item CDAP Documentation \cite{www-cdap-getting-started} provides introduction
 to CDAP platform.
\end{itemize}

\section{Representative Use Cases which can leverage CDAP}

CASK \cite{www-cask-io} is the company which provides commercial distribution
for CDAP. CASK has developed several applications using CDAP.
Some of the applications developed using CDAP are explained below
\begin{itemize}
\item CASK Hydrator \cite{www-cask-hydrator} is interactive application for
building, running and managing data pipelines for enterprise data lake.
CASK Hydrator is UI driven tool using which users can ingest data from
sources like traditional RDBMS, trasnform it,
aggregate it and finally store the data into permanent storage like HDFS.
CASK Hydrator provides UI drag-and-drop style abstraction to all of the above
 task.
\item Customer 360 is another representative application which can be built
using CDAP. Customer 360 applications analyzes
customer behavior data on various interaction platforms like mobile apps,
online communities, customer support portals,
and social media. CDAP can be used to ingest the data from these sources and
perform join, unification and aggregations to derive 360 degree view of
customer.
\end{itemize}

\section{Licensing}
CDAP is licensed \cite{www-cdap-license}under Apache License, Version2.0.

\section{Other Hadoop Application Development Platforms}
\begin{itemize}
\item Cascading \cite{www-cascading} is another application development
platform on Apache Hadoop. Cascading has many similar features like CDAP.
Cascading supports Java APIs, Data Processing APIs, Data Integration APIs,
Scheduler APIs, Relational Operations and scriptable interface. Cascading
also support many different Hadoop distributions.

\item Talend Big Data Integration \cite{www-talend} : Talend is integration
tool using which data can be extracted from source systems, stored on Hadoop
and processed in Hadoop. Although Talend is not exactly an application
development platform, lot of its features overlap with CDAP. Talend provides
visual interface for performing data ingestion and processing operations on
Hadoop
\end{itemize}

\section{Conclusion}
CDAP provides an application development platform over Apache Hadoop. Using
CDAP developers can code multiple layers of thier data pipeline in one
uniform language and tool. CDAP also can help to shield developers from
different Hadoop deployment options like Cloudera, Hortonworks and EMR.

\section*{Acknowledgements}

The authors thank Prof. Gregor von Laszewski for his technical guidance.


% Bibliography

\bibliography{references}

\end{document}
